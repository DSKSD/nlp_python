{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch5. Web Page Mining : 자연어 처리, 블로그 요약 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 작성자 : 김성동 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.1 자연어 처리의 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 문장의 끝 탐지(End of Sentence(EOS) Detection)\n",
    "2. 토큰화(Tokenization)\n",
    "3. 품사 태깅(Part-of-Speech Tagging)\n",
    "4. 군집화(Chunking)\n",
    "5. 추출(Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장 끝 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 단계는 텍스트를 의미 있는 문장의 모음으로 나눈다. NLTK 를 이용하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt = \"Mr. Green killed Colonel Mustard in the study with the candlestick. Mr. Green is not a very nice fellow.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 단위로 토큰화 시키기 ( 문장 끝 탐지 !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = nltk.tokenize.sent_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr. Green killed Colonel Mustard in the study with the candlestick.',\n",
       " 'Mr. Green is not a very nice fellow.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 단계는 각각의 문장을 토큰으로 분리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = [nltk.tokenize.word_tokenize(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mr.',\n",
       "  'Green',\n",
       "  'killed',\n",
       "  'Colonel',\n",
       "  'Mustard',\n",
       "  'in',\n",
       "  'the',\n",
       "  'study',\n",
       "  'with',\n",
       "  'the',\n",
       "  'candlestick',\n",
       "  '.'],\n",
       " ['Mr.', 'Green', 'is', 'not', 'a', 'very', 'nice', 'fellow', '.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_with_split = [s.split(' ') for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mr.',\n",
       "  'Green',\n",
       "  'killed',\n",
       "  'Colonel',\n",
       "  'Mustard',\n",
       "  'in',\n",
       "  'the',\n",
       "  'study',\n",
       "  'with',\n",
       "  'the',\n",
       "  'candlestick.'],\n",
       " ['Mr.', 'Green', 'is', 'not', 'a', 'very', 'nice', 'fellow.']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_with_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk의 토큰화는 split이 뛰어쓰기 기준으로 쪼갠 것과는 다르게 마침표까지 따로 토큰화 시켰다. 이 토큰화는 이전의 여백에 따라 분리하는 것과 똑같은 일을 하는 것으로 나타났다. 우리가 다음의 절에서 볼 것이지만, 이러한 토큰화는 좀더 많은 일을 할 수 있게 한다. 그리고 우리는 마침표가 문장의 끝을 나타내는 표시인지 또는 약어의 부분인지 구별하는 것이 항상 간단한 것이 아니라는 것을 이미 알고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 품사 태깅 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 단계는 각각의 토큰에 품사 정보를 지정한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tagged_tokens = [nltk.pos_tag(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Mr.', 'NNP'),\n",
       "  ('Green', 'NNP'),\n",
       "  ('killed', 'VBD'),\n",
       "  ('Colonel', 'NNP'),\n",
       "  ('Mustard', 'NNP'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('study', 'NN'),\n",
       "  ('with', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('candlestick', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NNP'),\n",
       "  ('Green', 'NNP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('not', 'RB'),\n",
       "  ('a', 'DT'),\n",
       "  ('very', 'RB'),\n",
       "  ('nice', 'JJ'),\n",
       "  ('fellow', 'NN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pos_tagged_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NNP : 그 토큰이 명사구의 일부분이면서 명사\n",
    "* VBD : 과거 시제 동사\n",
    "* JJ : 형용사\n",
    "\n",
    "... 품사 태그에 대한 정보 http://bit.ly/1a1n05o "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 군집화 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 단계는 문장에 있는 각각의 태그된 토큰을 분석하고, 논리적인 개념을 표현하는 토큰 집합을 모은다. 이는 통계적으로 연어를 분석하는 것과는 완전히 다른 방법이다. NLTK의 chunk.RegexpParser를 통해 직접 문법을 정의할 수 있으나 이 장의 범위를 넘어서므로, NLP with Python 9장(Building Feature Based Grammars)의 내용을 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추출 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 단계는 각각의 집합을 분석하여 실체정보에 대해 이름(사람, 회사, 장소 등)을 붙여 집합들을 태깅한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ne_chunks = nltk.ne_chunk_sents(pos_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Mr./NNP)\n",
      "  (PERSON Green/NNP)\n",
      "  killed/VBD\n",
      "  (ORGANIZATION Colonel/NNP Mustard/NNP)\n",
      "  in/IN\n",
      "  the/DT\n",
      "  study/NN\n",
      "  with/IN\n",
      "  the/DT\n",
      "  candlestick/NN\n",
      "  ./.)\n",
      "(S\n",
      "  (PERSON Mr./NNP)\n",
      "  (ORGANIZATION Green/NNP)\n",
      "  is/VBZ\n",
      "  not/RB\n",
      "  a/DT\n",
      "  very/RB\n",
      "  nice/JJ\n",
      "  fellow/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "for chunk in ne_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 출력이 무엇을 의미하는지 해독하기 위해 아직은 너무 몰입하지 마라. 요약하면 여기에서는 토큰들을 모아서 집합을 만들고, 그것들을 특정 형태의 실체정보로 분류하고자 했다. \"Mr. Green\"은 사람으로 분류되었으나, 불행히도 \"Colonel Mustard\"는 회사로 분류된 것을 볼 수 있다. NLTK를 가지고 자연 언어를 계속해서 탐구하는 것이 가치가 있더라도, 이러한 수준의 개입은 여기서 우리의 진정한 목적은 아니다~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.2 인간 언어 데이터에서 문장 탐지 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 탐지가 NLP 스택을 만들 때 여러분이 생각하는 첫 번째 작업이라는 것을 고려하여 문장 탐지부터 해보자!\n",
    "O'Reilly의 Radar 블로그에서 포스트를 수집하기 위해 \"feedparser\" 모듈을 사용하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "피드를 파싱하여 블로그 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import feedparser\n",
    "from bs4 import BeautifulStoneSoup\n",
    "from nltk import clean_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEED_URL = 'http://feeds.feedburner.com/oreilly/radar/atom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean_html은 태그를 제거하고 \n",
    "# BeautifulStoneSoup은 HTML 엔티티를 변환한다. ex. I&#39;ve 나 <br/> 같은 것들 제거\n",
    "def cleanHtml(html):\n",
    "    return BeautifulSoup(html, 'lxml').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp = feedparser.parse(FEED_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 32 entries from 'All - O'Reilly Media'\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetched %s entries from '%s'\" % (len(fp.entries[0].title), fp.feed.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blog_posts = []\n",
    "for e in fp.entries:\n",
    "    blog_posts.append({'title' : e.title, 'content' : cleanHtml(e.content[0].value), \n",
    "                       'link' : e.links[0].href})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('feed.json', 'w')\n",
    "f.write(json.dumps(blog_posts, indent=1))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "블로그 데이터의 언어 처리를 위해 NLTK의 NLP 툴 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BLOG_DATA = \"feed.json\"\n",
    "blog_data = json.loads(open(BLOG_DATA).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 필요한 대로 불용어 리스트를 변경한다.\n",
    "# 여기서는 일반적인 구두점과 축약 구무을 추가했다.\n",
    "stop_words = nltk.corpus.stopwords.words('english') + ['.',\n",
    "                                                      ',',\n",
    "                                                      '--',\n",
    "                                                      '\\'s',\n",
    "                                                      '?',\n",
    "                                                      ')',\n",
    "                                                      '(',\n",
    "                                                      ':',\n",
    "                                                      '\\'',\n",
    "                                                      '\\'re',\n",
    "                                                      '\"',\n",
    "                                                      '-',\n",
    "                                                      '}',\n",
    "                                                      '{',\n",
    "                                                      u'-',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for post in blog_data:\n",
    "    sentences = nltk.tokenize.sent_tokenize(post['content'])\n",
    "    \n",
    "    words = [w.lower() for sentence in sentences for w in nltk.tokenize.word_tokenize(sentence)]\n",
    "    \n",
    "    fdist = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 문장 단위로 쪼개고 그 다음 하나씩 가져와서 토큰화 시키고 소문자화 해서 words에 다 담고, freqdist도 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 기초적인 상태값\n",
    "\n",
    "num_words = sum([i[1] for i in fdist.items()]) # key-value pair를 하나씩 받아와서 value들만 합침. 즉 토큰의 갯수\n",
    "num_unique_words = len(fdist.keys()) # key들 즉 token의 중복 제거한 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hapaxes는 단 한 번만 나타나는 단어들\n",
    "\n",
    "num_hapaxes = len(fdist.hapaxes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 113 85\n"
     ]
    }
   ],
   "source": [
    "print(num_words, num_unique_words, num_hapaxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_10_words_sans_stop_words = [w for w in fdist.items() if w[0] not in stop_words][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('helped', 1),\n",
       " ('report', 1),\n",
       " ('lore', 1),\n",
       " ('google', 2),\n",
       " ('business', 1),\n",
       " ('work', 2),\n",
       " ('create', 1),\n",
       " ('worked', 1),\n",
       " ('behind', 1),\n",
       " ('best', 1)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_words_sans_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction to OKRs\n",
      "\tNum Sentences:           11\n",
      "\tNum Words:               193\n",
      "\tNum Unique Words:        113\n",
      "\tNum Hapaxes:             85\n",
      "\tTop 10 Most Frequent Words (sans stop words):\n",
      "\t\t helped (1)\n",
      "\t\treport (1)\n",
      "\t\tlore (1)\n",
      "\t\tgoogle (2)\n",
      "\t\tbusiness (1)\n",
      "\t\twork (2)\n",
      "\t\tcreate (1)\n",
      "\t\tworked (1)\n",
      "\t\tbehind (1)\n",
      "\t\tbest (1)\n"
     ]
    }
   ],
   "source": [
    "print(post['title'])\n",
    "print('\\tNum Sentences:'.ljust(25), len(sentences))\n",
    "print('\\tNum Words:'.ljust(25), num_words)\n",
    "print('\\tNum Unique Words:'.ljust(25), num_unique_words)\n",
    "print('\\tNum Hapaxes:'.ljust(25), num_hapaxes)\n",
    "print('\\tTop 10 Most Frequent Words (sans stop words):\\n\\t\\t',\n",
    "      '\\n\\t\\t'.join(['%s (%s)' % (w[0], w[1]) for w in top_10_words_sans_stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK는 토큰화를 위해 여러 개의 옵션을 제공하지만, 가장 유용한 것에 대한 추천을 하지 않고 있다. 이 책이 쓰여진 시점에 있어서 문장 탐지도구는 \"PunktSentenceTokenizer\"이고, 단어 토큰화 도구는 \"TreebankWordTokenizer\"다. 이들 각각에 대해 간단히 살펴보자. \n",
    "\n",
    "내부적으로, PunktSentenceTokenizer는 연어 패턴의 부분으로서 약어를 탐지할 수 있는 것에 주로 의존하고, 구두점 사용의 패턴을 고려하여 문장을 지능적으로 분석하기 위해 일부 정규표현을 사용한다. PunkSentenceTokenizer 로직 내부에 대한 완벽한 설명은 이 책의 범위를 넘어선다. ... 이 알고리즘은 텍스트를 문장으로 분리하기 위한 적절한 변수를 찾기 위해 텍스트에 나타난 대문자 사용, 토큰의 중복 발생 등과 같은 특정 형태를 검사한다.\n",
    "\n",
    "텍스트를 여백 기준으로 분리함으로써 토큰을 생성하는 NLTK의 WhitespaceTokenizer는 가장 간단한 단어 토큰화 도구인데, 여러분은 이미 여백을 기준으로 분리하는 것의 단점에 대해 알고 있다. 대신 NLTK는 현재 \"TreebankWordTokenizer를 추천한다. ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.3 문서 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장들 내에서 문장 탐지와 빈도 분석에 기반을 둔 문서 요약 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BLOG_DATA = 'feed.json'\n",
    "\n",
    "N = 100 # 처리할 단어들의 개수\n",
    "CLUSTER_THRESHOLD = 5 # 처리할 단어들 간의 거리\n",
    "TOP_SENTENCES = 5 # 상위 n개 요약을 리턴할 문장들의 개수\n",
    "\n",
    "# H.P. Luhn의 \"The Automatic Creation of Literature Abstracts\"에서 가져온 접근 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 문장의 토큰이 중요단어 리스트에 있는 토큰을 얼마나 포함하는지에 따라 스코어를 계산한다.\n",
    "def _score_sentences(sentences, important_words):\n",
    "    scores = []\n",
    "    sentence_idx = -1\n",
    "    \n",
    "    for s in [nltk.tokenize.word_tokenize(s) for s in sentences]:\n",
    "        sentence_idx += 1\n",
    "        word_idx = []\n",
    "        \n",
    "        for w in important_words:\n",
    "            try:\n",
    "                # 문장에서 임의의 중요 단어가 나타난 곳에 대한 인덱스를 계산한다.\n",
    "                \n",
    "                word_idx.append(s.index(w))\n",
    "            \n",
    "            except: # w는 이런 특정한 문장에 없음\n",
    "                pass\n",
    "            \n",
    "        word_idx.sort()\n",
    "            \n",
    "        # 일부 문장들은 중요한 단어를 포함하고 있지 않을 수도 있다.\n",
    "        if len(word_idx) == 0: continue\n",
    "        \n",
    "        # 단어의 인덱스를 이용하고 최대 거리 임계치를 활용하여 \n",
    "        # 두 연속된 단어들에 대한 클러스터를 계산한다.\n",
    "        \n",
    "        clusters = []\n",
    "        cluster = [word_idx[0]]\n",
    "        i = 1\n",
    "        while i < len(word_idx):\n",
    "            if word_idx[i] - word_idx[i-1] < CLUSTER_THRESHOLD:\n",
    "                cluster.append(word_idx[i])\n",
    "            else:\n",
    "                clusters.append(cluster[:])\n",
    "                cluster = [word_idx[i]]\n",
    "            i += 1\n",
    "        clusters.append(cluster)\n",
    "        \n",
    "        # 각각의 클러스터에 대한 점수를 계산한다.\n",
    "        # 클러스터에 대한 최대 점수가 문장의 점수다.\n",
    "        \n",
    "        max_cluster_score = 0\n",
    "        for c in clusters:\n",
    "            significant_words_in_cluster = len(c)\n",
    "            total_words_in_cluster = c[-1] - c[0] + 1\n",
    "            score = 1.0 * significant_words_in_cluster*significant_words_in_cluster / total_words_in_cluster\n",
    "            \n",
    "            if score > max_cluster_score:\n",
    "                max_cluster_score = score\n",
    "        \n",
    "        scores.append((sentence_idx, score))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summarize(txt):\n",
    "    sentences = [s for s in nltk.tokenize.sent_tokenize(txt)]\n",
    "    normalized_sentences = [s.lower() for s in sentences]\n",
    "    \n",
    "    words = [w.lower() for sentence in normalized_sentences for w in nltk.tokenize.word_tokenize(sentence)]\n",
    "    \n",
    "    fdist = nltk.FreqDist(words)\n",
    "    \n",
    "    top_n_words = [w[0] for w in fdist.items() if w[0] not in nltk.corpus.stopwords.words('english')][:N]\n",
    "    \n",
    "    scored_sentences = _score_sentences(normalized_sentences, top_n_words)\n",
    "    \n",
    "    # 요약 접근 방법 1:\n",
    "    # 평균 점수에 표준편차(std dev)를 더한 것을 필터로 하여\n",
    "    # 중요하지 않은 문장들을 필터링한다.\n",
    "\n",
    "    avg = numpy.mean([s[1] for s in scored_sentences])\n",
    "    std = numpy.std([s[1] for s in scored_sentences])\n",
    "    mean_scored = [(sent_idx, score) for (sent_idx, score) in scored_sentences if score > avg + 0.5*std]\n",
    "    \n",
    "    # 요약 접근 방법 2:\n",
    "    # 또 다른 접근은 문장에서 상위 N개만 리턴하는 것이다.\n",
    "    \n",
    "    top_n_scored = sorted(scored_sentences, key=lambda s: s[1])[-TOP_SENTENCES:]\n",
    "    top_n_scored = sorted(top_n_scored, key=lambda s: s[0])\n",
    "    \n",
    "    # post 객체에 요약한 내용을 추가한다.\n",
    "    return dict(top_n_summary=[sentences[idx] for (idx, score) in top_n_scored],\n",
    "               mean_scored_summary=[sentences[idx] for (idx, score) in mean_scored])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blog_data = json.loads(open(BLOG_DATA).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Four short links: 19 August 2016\n",
      "================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Machine Learning Unconference, Sgt Augmento, TCP Puzzles, and Open Source PowerShell\n",
      "\n",
      "OpenAI's Machine Learning Unconference -- Oct 7-8 in SF. Sgt Augmento -- Bruce Sterling's new story about robots taking our jobs. (via Cory Doctorow)\n",
      "\n",
      "TCP Puzzlers -- good stuff! PowerShell Open Sourced -- it's somewhat a shell, but mostly a scripting language for automation. Continue reading Four short links: 19 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Machine Learning Unconference, Sgt Augmento, TCP Puzzles, and Open Source PowerShell\n",
      "\n",
      "OpenAI's Machine Learning Unconference -- Oct 7-8 in SF. (via Cory Doctorow)\n",
      "\n",
      "TCP Puzzlers -- good stuff!\n",
      "\n",
      "What would Alexa do?\n",
      "====================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "From now on, I'm expected to interact with the app by touching the screen. I'm forced to switch modes unnecessarily between voice and touch. There's real evidence of clear and consistent human design anticipation throughout the product. I can't just switch back and forth! Conversational interfaces are only one of many ways that businesses are facing tectonic shifts as a result of new technology.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "I can \"stack\" multiple interactions, and have \"her\" guess with some accuracy which context a subsequent interaction belongs to. This is partly a power issue–unlike an Amazon Echo, the phone has battery life considerations–but it is also a privacy issue. Good so far. From now on, I'm expected to interact with the app by touching the screen. \"’Obviously 5 Believers’.\" But even if that intervening screen weren't there, you can see that the handoff model, where the conversational agent passes control to an old-school smartphone app, introduces needless complexity into the interface. I'm forced to switch modes unnecessarily between voice and touch. There's real evidence of clear and consistent human design anticipation throughout the product. Designers who carry over too much baggage from the touch screen era, and don't learn to think natively about speech interfaces, are likely to build poorly thought-out hybrid experiences like the one that keeps me from using speech as an effective interface to many of the functions of my Android phone. I can't just switch back and forth! Conversational interfaces are only one of many ways that businesses are facing tectonic shifts as a result of new technology.\n",
      "\n",
      "Take the 2017 Data Science Salary Survey\n",
      "========================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "As a data professional, you are invited to share your valuable insights. Help us gain insight into the demographics, work environments, tools, and compensation of practitioners in our growing field. All responses are reported in aggregate to assure your anonymity. The survey will require approximately 5-10 minutes to complete.All responses to this survey are reported in aggregate to assure your anonymity. Take the survey\n",
      "Loading...Continue reading Take the 2017 Data Science Salary Survey.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Help us gain insight into the demographics, work environments, tools, and compensation of practitioners in our growing field. Take the survey\n",
      "Loading...Continue reading Take the 2017 Data Science Salary Survey.\n",
      "\n",
      "What are bots? Here’s the background.\n",
      "=====================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "O’Reilly Bots Podcast: Why AI-driven chatbots are a big deal right now.We’re launching a new pop-up podcast about bots. In this first episode of the O’Reilly Bots Podcast, I’m joined by Peter Skomoroch to talk background: why everyone is suddenly interested in bots and what they promise to do, and what sorts of applications are beginning to emerge.Continue reading What are bots? Here’s the background..\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "O’Reilly Bots Podcast: Why AI-driven chatbots are a big deal right now.We’re launching a new pop-up podcast about bots.\n",
      "\n",
      "Doreen Lorenzo on design becoming the core DNA of an organization\n",
      "=================================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "The O’Reilly Design Podcast:  Designing women, avoiding the buzzword curse, and the F word. In this week’s Design Podcast, I sit down with former president of Frog, Doreen Lorenzo. Lorenzo is currently the director for the Center of Integrated Design at the University of Texas at Austin. We talk about the design in education, women in design, and failing fast versus learning fast. Continue reading Doreen Lorenzo on design becoming the core DNA of an organization.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "The O’Reilly Design Podcast:  Designing women, avoiding the buzzword curse, and the F word.\n",
      "\n",
      "miniPCR: Enabling the era of personal DNA\n",
      "=========================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Three years ago, we set out to make personal DNA tools that everyone could use. miniPCR started as a maker project, and after a design and prototyping phase, we launched the DNA Discovery System on Kickstarter in 2014. The miniPCR DNA Discovery System is a portable, personal DNA lab that anyone can use. For example, lab-based researchers may need greater PCR capacity and educators may chose to start with the simpler techniques of DNA gel electrophoresis and visualization. Field-based users may opt to power miniPCR with rechargeable batteries, and couple it to downstream sequencers foregoing gel electrophoresis components.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "The Discovery System is a portable, personal DNA lab that anyone can use. Three years ago, we set out to make personal DNA tools that everyone could use. miniPCR started as a maker project, and after a design and prototyping phase, we launched the DNA Discovery System on Kickstarter in 2014. The miniPCR DNA Discovery System is a portable, personal DNA lab that anyone can use. For example, lab-based researchers may need greater PCR capacity and educators may chose to start with the simpler techniques of DNA gel electrophoresis and visualization. Field-based users may opt to power miniPCR with rechargeable batteries, and couple it to downstream sequencers foregoing gel electrophoresis components.\n",
      "\n",
      "Four short links: 18 August 2016\n",
      "================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "(gitxiv) -- In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. A Persona-Based Neural Conversation Model -- We present persona-based models for handling the issue of speaker consistency in neural response generation. A dyadic speaker-addressee model captures properties of interactions between two interlocutors. Altogether, our results indicate that information about human assets is causally important for the funding of early-stage firms, and hence, for entrepreneurial success. Continue reading Four short links: 18 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "(gitxiv) -- In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. A Persona-Based Neural Conversation Model -- We present persona-based models for handling the issue of speaker consistency in neural response generation. A dyadic speaker-addressee model captures properties of interactions between two interlocutors.\n",
      "\n",
      "What is successful automation?\n",
      "==============================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "He is the head of ThoughtWorks’ European practice for Continuous Delivery and DevOps, helping clients find more effective ways of building and managing infrastructure operations. What is \"Infrastructure as Code\"? Infrastructure as Code (IaC) is about applying tools and practices from software development to managing infrastructure. What is the relationship between IaC and DevOps? When I started out I did many of the things I see other people do today—for instance, treating server configuration tools like Puppet and Chef as a glorified scripting language.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "He is the head of ThoughtWorks’ European practice for Continuous Delivery and DevOps, helping clients find more effective ways of building and managing infrastructure operations. I sat down with Kief to discuss his thoughts on infrastructure. What is \"Infrastructure as Code\"? Infrastructure as Code (IaC) is about applying tools and practices from software development to managing infrastructure. What is the relationship between IaC and DevOps? When I started out I did many of the things I see other people do today—for instance, treating server configuration tools like Puppet and Chef as a glorified scripting language.\n",
      "\n",
      "Cory Doctorow on legally disabling DRM (for good)\n",
      "=================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "The O’Reilly Security Podcast: The chilling effects of DRM, nascent pro-security industries, and the narrative power of machines.In this episode, I talk with Cory Doctorow, a journalist, activist, and science fiction writer. We discuss the EFF lawsuit against the U.S. government, the prospect for a whole new industry of pro-security businesses, and the new W3C DRM specification.Continue reading Cory Doctorow on legally disabling DRM (for good).\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "The O’Reilly Security Podcast: The chilling effects of DRM, nascent pro-security industries, and the narrative power of machines.In this episode, I talk with Cory Doctorow, a journalist, activist, and science fiction writer.\n",
      "\n",
      "The Secrets Behind Great One-on-One Meetings\n",
      "============================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Learn best practices for one-on-one meetings that promote productivity and team loyalty within your business\n",
      "These regular meetings improve team communication, identify fixable issues before they transform into big problems, and increase employee loyalty. Wonderful idea. But when you’re sitting there, staring at each other, what are you supposed to say?Continue reading The Secrets Behind Great One-on-One Meetings.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Learn best practices for one-on-one meetings that promote productivity and team loyalty within your business\n",
      "These regular meetings improve team communication, identify fixable issues before they transform into big problems, and increase employee loyalty.\n",
      "\n",
      "Four short links: 17 August 2016\n",
      "================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Thinking Mathematics, Document Rectification, Human Misjudgement, and Joel Test for Data Science\n",
      "\n",
      "What It's Like to Know Higher Mathematics (Quora) -- a fascinating glimpse at how mathematicians think. This makes the total time you spend in life reveling in your mastery of something quite brief. Fast Document Rectification and Enhancement (Dropbox) -- how this useful thing is done, for image processing enthusiasts. The Psychology of Human Misjudgement (PDF) -- interesting run-through of the fallibilities in our judgement. Continue reading Four short links: 17 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Thinking Mathematics, Document Rectification, Human Misjudgement, and Joel Test for Data Science\n",
      "\n",
      "What It's Like to Know Higher Mathematics (Quora) -- a fascinating glimpse at how mathematicians think. Fast Document Rectification and Enhancement (Dropbox) -- how this useful thing is done, for image processing enthusiasts.\n",
      "\n",
      "Common questions in data science interviews\n",
      "===========================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Katie Kent and Jonathan Dinu discuss topics you may be asked about in data science interviews, depending on the types of data science jobs you interview for.Continue reading Common questions in data science interviews.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "\n",
      "\n",
      "The microservices value proposition\n",
      "===================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Examine the benefits of microservice architecture and techniques to achieve them. The microservice architectural style was defined based on common patterns observed across a number of pioneering organizations. These organizations did not consciously implement a microservice architecture. They evolved to it in pursuit of specific goals. In this chapter, we will explore the common benefits of microservice architecture and how they drive the higher-order goals from not available—speed, safety, and scale; illustrate how the goals of microservice architecture deliver business value; define a maturity model for microservice architecture benefits and goals; and finally, apply this information using a goal-oriented approach to microservice architecture.Continue reading The microservices value proposition.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "The microservice architectural style was defined based on common patterns observed across a number of pioneering organizations.\n",
      "\n",
      "2016 European Software Development Salary Survey\n",
      "================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "This provided us with the opportunity to explore the software-development world—and the careers that propel it—in great detail. Some key findings include:\n",
      "\n",
      "Top languages currently used professionally in the sample: JavaScript, HTML, CSS, Java, Bash, and Python. The most common languages that respondents stated they intend to learn in the next 1–2 years were Go, Swift, Python, and Scala. from this report, and we encourage you to try plugging your own data points into the model. We\n",
      "hope you will learn something new (and useful) from this\n",
      "report, and encourage you to try plugging your own data\n",
      "points into the model.Continue reading 2016 European Software Development Salary Survey.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "This provided us with the opportunity to explore the software-development world—and the careers that propel it—in great detail. Some key findings include:\n",
      "\n",
      "Top languages currently used professionally in the sample: JavaScript, HTML, CSS, Java, Bash, and Python. We\n",
      "hope you will learn something new (and useful) from this\n",
      "report, and encourage you to try plugging your own data\n",
      "points into the model.Continue reading 2016 European Software Development Salary Survey.\n",
      "\n",
      "Docker for Java developers\n",
      "==========================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Learn how to achieve faster startup and deployments on both Windows, Mac OS X, and Linux, and understand how these containers improve portability across machines. The usual steps to deploy a Java application involve using a script that downloads and installs the operating system package such as JDK on a machine—whether physical or virtual. These applications are typically deployed on a virtual machine (VM). Containers provide several benefits over traditional VM-based deployments. They also improve portability across machines and reduce the impedance mismatch between dev, test, and prod environments.Continue reading Docker for Java developers.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Learn how to achieve faster startup and deployments on both Windows, Mac OS X, and Linux, and understand how these containers improve portability across machines. The usual steps to deploy a Java application involve using a script that downloads and installs the operating system package such as JDK on a machine—whether physical or virtual. These applications are typically deployed on a virtual machine (VM). They also improve portability across machines and reduce the impedance mismatch between dev, test, and prod environments.Continue reading Docker for Java developers.\n",
      "\n",
      "In Search of Database Nirvana\n",
      "=============================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Rohit Jain takes an in-depth look at the possibilities and the challenges for companies that long for a single query engine to rule them all. The Swinging Database Pendulum\n",
      "It often seems like the IT industry sways back and forth on technology decisions. About a decade ago, new web-scale companies were gathering more data than ever before and needed new levels of scale and performance from their data systems. There were Relational Database Management Systems (RDBMSs) that could scale on Massively-Parallel Processing (MPP) architectures, such as the following:Continue reading In Search of Database Nirvana.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "There were Relational Database Management Systems (RDBMSs) that could scale on Massively-Parallel Processing (MPP) architectures, such as the following:Continue reading In Search of Database Nirvana.\n",
      "\n",
      "Easy, reproducible reports with R\n",
      "=================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Garrett Grolemund demonstrates how to use R Markdown to combine code and text into a single .Rmd file to generate polished reports automatically in a variety of formats.Continue reading Easy, reproducible reports with R.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "\n",
      "\n",
      "Four short links: 16 August 2016\n",
      "================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Inferential Thinking, Free Coding School, Technical Wealth, and Social Linked Data\n",
      "\n",
      "Computational and Inferential Thinking -- textbook for the Foundations of Data Science class at UC Berkeley. Ars Covers 42 -- free coding school with a really interesting approach (aims to provide social mobility). Building Technical Wealth -- work to fix things that make developers less productive because the value from today's development compounds. MIT Solid -- (derived from \"social linked data\") is a proposed set of conventions and tools for building decentralized social applications based on Linked Data principles. Continue reading Four short links: 16 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Inferential Thinking, Free Coding School, Technical Wealth, and Social Linked Data\n",
      "\n",
      "Computational and Inferential Thinking -- textbook for the Foundations of Data Science class at UC Berkeley. Ars Covers 42 -- free coding school with a really interesting approach (aims to provide social mobility). Building Technical Wealth -- work to fix things that make developers less productive because the value from today's development compounds. MIT Solid -- (derived from \"social linked data\") is a proposed set of conventions and tools for building decentralized social applications based on Linked Data principles.\n",
      "\n",
      "How continuous delivery helps security keep up with change\n",
      "==========================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Amazon has thousands of small (“two pizza”) engineering teams working independently and continuously deploying changes across their infrastructure. A major problem that almost all organizations face is that even when they know that they have a serious security vulnerability in a system, they can’t get the fix out fast enough to stop attackers from exploiting the vulnerability. Using data from 2013 and 2014, WhiteHat found that 35 percent of finance and insurance websites are “always vulnerable,” meaning that these sites had at least one serious vulnerability exposed every single day of the year. Continuous Delivery, and collaboration between developers and operations and infosec staff working closely together, can close vulnerability windows. If you are deploying somewhere on your net, it doesn’t look like a special action taken against the attackers.”\n",
      "\n",
      "\n",
      "\n",
      "[1] “AWS re:Invent 2015 | (DVO202) DevOps at Amazon: A Look at Our Tools and Proesses.” https://www.youtube.com/watch?v=esEFaY0FDKc\n",
      "\n",
      "\n",
      "Continue reading How continuous delivery helps security keep up with change.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Amazon has thousands of small (“two pizza”) engineering teams working independently and continuously deploying changes across their infrastructure. [1]\n",
      "So much change so fast...\n",
      "How can security possibly keep up with this rate of change? Use the speed of continuous delivery to your advantage\n",
      "The speed at which DevOps moves can seem scary to infosec analysts and auditors. A major problem that almost all organizations face is that even when they know that they have a serious security vulnerability in a system, they can’t get the fix out fast enough to stop attackers from exploiting the vulnerability. The longer vulnerabilities are exposed, the more likely the system will be, or has already been, attacked. Using data from 2013 and 2014, WhiteHat found that 35 percent of finance and insurance websites are “always vulnerable,” meaning that these sites had at least one serious vulnerability exposed every single day of the year. The stats for other industries and government organizations were even worse. Continuous Delivery, and collaboration between developers and operations and infosec staff working closely together, can close vulnerability windows. To some extent relying on change to confuse attackers is “security through obscurity,” which is generally a weak defensive position. If you are deploying somewhere on your net, it doesn’t look like a special action taken against the attackers.”\n",
      "\n",
      "\n",
      "\n",
      "[1] “AWS re:Invent 2015 | (DVO202) DevOps at Amazon: A Look at Our Tools and Proesses.” https://www.youtube.com/watch?v=esEFaY0FDKc\n",
      "\n",
      "\n",
      "Continue reading How continuous delivery helps security keep up with change.\n",
      "\n",
      "5 tips for improving availability\n",
      "=================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "These availability problems often arise from the areas you least expect, and some of the most serious availability problems can originate from extremely benign sources. Tip #1: Build with failure in mind\n",
      "As Werner Vogels, CTO of Amazon, says, “Everything fails all the time.” Plan on your applications and services failing. Synthetic testing \n",
      "To examine in real time how your application is functioning from the perspective of your users, in order to catch problems customers might see before they actually see them. Additionally, you should establish processes and procedures that your team can follow to help diagnose issues and easily fix common failure scenarios. [1] Risk management is discussed extensively in Part II of Architecting for Scale.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "These availability problems often arise from the areas you least expect, and some of the most serious availability problems can originate from extremely benign sources. Many of these are systemic problems, not merely code problems. Tip #1: Build with failure in mind\n",
      "As Werner Vogels, CTO of Amazon, says, “Everything fails all the time.” Plan on your applications and services failing. Can you handle excessive load on your system? Specifically, this might mean:\n",
      "\n",
      "Architect in the ability to increase the size and capacity of your databases. But as systems become more and more complicated, this becomes less and less possible. Synthetic testing \n",
      "To examine in real time how your application is functioning from the perspective of your users, in order to catch problems customers might see before they actually see them. Additionally, you should establish processes and procedures that your team can follow to help diagnose issues and easily fix common failure scenarios. Additionally, they can provide useful follow-up diagnosis information to your engineering teams to help them deduce the root cause of common ailments. These standard processes and procedures should be part of a support manual available to all team members who handle oncall responsibility. [1] Risk management is discussed extensively in Part II of Architecting for Scale.\n",
      "\n",
      "Thinking with containers: 3 tips for moving to Docker\n",
      "=====================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "It doesn't actually virtualize at all. That tool allowed us as a company to empower anyone to redeploy an application, even without knowing anything about the application. Try to see how you can potentially use Docker to help make that small piece better. Verify that the test works, and then destroy the container. It's harder to completely understand how you can best use it.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "This episode of the O’Reilly Podcast features my discussion with Sean P. Kane, lead site reliability engineer at New Relic. It doesn't actually virtualize at all. That tool allowed us as a company to empower anyone to redeploy an application, even without knowing anything about the application. Try to see how you can potentially use Docker to help make that small piece better. Verify that the test works, and then destroy the container. It doesn't allow you to spend time actually getting to understand the technology of Docker and what it's good at. What’s the best way to get started working with containers? It's harder to completely understand how you can best use it.\n",
      "\n",
      "Embracing disposable processes\n",
      "==============================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Building cloud-native apps that start rapidly and shut down gracefully.In Beyond the Twelve-Factor App, I present a new set of guidelines that builds on Heroku’s original 12 factors and reflects today’s best practices for building cloud-native applications. I have changed the order of some to indicate a deliberate sense of priority, and added factors such as telemetry, security, and the concept of “API first” that should be considerations for any application that will be running in the cloud. These new 15-factor guidelines are:\n",
      "\n",
      "One codebase, one application\n",
      "API first\n",
      "Dependency management\n",
      "Design, build, release, and run\n",
      "Configuration, credentials, and code\n",
      "Logs\n",
      "Disposability\n",
      "Backing services\n",
      "Environment parity\n",
      "Administrative processes\n",
      "Port binding\n",
      "Stateless processes\n",
      "Concurrency\n",
      "Telemetry\n",
      "Authentication and authorization\n",
      "\n",
      "Disposability is the ninth of the original 12 factors. If you are bringing up an application, and it takes minutes to get into a steady state, in today’s world of high traffic that could mean hundreds or thousands of requests get denied while the application is starting. More importantly, depending on the platform on which your application is deployed, such a slow startup time might actually trigger alerts or warnings as the application fails its health check.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Building cloud-native apps that start rapidly and shut down gracefully.In Beyond the Twelve-Factor App, I present a new set of guidelines that builds on Heroku’s original 12 factors and reflects today’s best practices for building cloud-native applications. I have changed the order of some to indicate a deliberate sense of priority, and added factors such as telemetry, security, and the concept of “API first” that should be considerations for any application that will be running in the cloud. These new 15-factor guidelines are:\n",
      "\n",
      "One codebase, one application\n",
      "API first\n",
      "Dependency management\n",
      "Design, build, release, and run\n",
      "Configuration, credentials, and code\n",
      "Logs\n",
      "Disposability\n",
      "Backing services\n",
      "Environment parity\n",
      "Administrative processes\n",
      "Port binding\n",
      "Stateless processes\n",
      "Concurrency\n",
      "Telemetry\n",
      "Authentication and authorization\n",
      "\n",
      "Disposability is the ninth of the original 12 factors. If you are bringing up an application, and it takes minutes to get into a steady state, in today’s world of high traffic that could mean hundreds or thousands of requests get denied while the application is starting. More importantly, depending on the platform on which your application is deployed, such a slow startup time might actually trigger alerts or warnings as the application fails its health check.\n",
      "\n",
      "Clair: Clarity with container security scanning\n",
      "===============================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Learn about Clair, a new open source tool to monitor the security of containers and automatically detect vulnerabilities in Docker and rkt containers.Continue reading Clair: Clarity with container security scanning.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "\n",
      "\n",
      "The UK needs to double down on the GDS, not dismantle it\n",
      "========================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "According to the article in Computer Weekly that lays out the plans to roll back the authority of the GDS, the intent is “to break up GDS and return to the sort of model that existed before the 2010 general election, where a much smaller central policy team was responsible for strategy and standards, with all delivery returned to Whitehall departments.” This is a serious mistake. It is indeed essential to get the departments involved, but they must not return to the pre-2010 practice of outsourcing IT to vendors rather than building the internal delivery capability that keeps vendors honest and makes sure that the government itself has the ability to deliver on key services. The VA’s post about how they made the new application a success was unequivocal: “prioritize users, and engage them early and often.” If that sounds a lot like the first several points of the GDS’s Digital Service Standard, that’s not a coincidence. The Departments of Health and Human Services, Education, Homeland Security, and many others all have similar stories, and they’re starting to add up to something big enough to be the new normal. They should double down on the enormous gains that the GDS has already made in modernizing government IT instead of throwing away their advantage and looking on in envy as other nations finish what they started.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "New Zealand, Israel, Mexico, and several other countries are following suit. According to the article in Computer Weekly that lays out the plans to roll back the authority of the GDS, the intent is “to break up GDS and return to the sort of model that existed before the 2010 general election, where a much smaller central policy team was responsible for strategy and standards, with all delivery returned to Whitehall departments.” This is a serious mistake. It is indeed essential to get the departments involved, but they must not return to the pre-2010 practice of outsourcing IT to vendors rather than building the internal delivery capability that keeps vendors honest and makes sure that the government itself has the ability to deliver on key services. The role of the GDS should not be replaced by work in the departments, but augmented by departmental Digital Services that work closely with the central coordinating team. The VA’s post about how they made the new application a success was unequivocal: “prioritize users, and engage them early and often.” If that sounds a lot like the first several points of the GDS’s Digital Service Standard, that’s not a coincidence. The Departments of Health and Human Services, Education, Homeland Security, and many others all have similar stories, and they’re starting to add up to something big enough to be the new normal. They should double down on the enormous gains that the GDS has already made in modernizing government IT instead of throwing away their advantage and looking on in envy as other nations finish what they started.\n",
      "\n",
      "Four short links: 15 August 2016\n",
      "================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "(via ADT)\n",
      "\n",
      "CartPole -- OpenAI's gym version of a classic better-if-learned-than-told programming problem. For more, see Mat Kelcey. Traffic Camera Security -- To summarize, we discovered three major weaknesses in the road agency’s traffic infrastructure deployment: 1. Devices on the network lack secure authentication due to the use of default usernames and passwords. Continue reading Four short links: 15 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "(via ADT)\n",
      "\n",
      "CartPole -- OpenAI's gym version of a classic better-if-learned-than-told programming problem. Traffic Camera Security -- To summarize, we discovered three major weaknesses in the road agency’s traffic infrastructure deployment: 1. Devices on the network lack secure authentication due to the use of default usernames and passwords. Continue reading Four short links: 15 August 2016.\n",
      "\n",
      "Four short links: 12 August 2016\n",
      "================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "DDoSCoin: Cryptocurrency with a Malicious Proof-of-Work -- brilliant Usenix paper! A Honeypot for Assholes -- a history of Twitter's failure to prosecute trolls. I didn't realize how much was inspired by the Free Speech cause in the beginning. It's interesting just how far the conversation about conversations has progressed since then. Continue reading Four short links: 12 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "DDoSCoin: Cryptocurrency with a Malicious Proof-of-Work -- brilliant Usenix paper! A Honeypot for Assholes -- a history of Twitter's failure to prosecute trolls. Continue reading Four short links: 12 August 2016.\n",
      "\n",
      "Introduction to Local Interpretable Model-Agnostic Explanations (LIME)\n",
      "======================================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "See Figure 3 for an example of how LIME works for image classification. We take the image on the left and divide it into interpretable components (contiguous superpixels). As illustrated in Figure 4, we then generate a data set of perturbed instances by turning some of the interpretable components “off” (in this case, making them gray). For each perturbed instance, we get the probability that a tree frog is in the image according to the model. It also sheds light on why \"pool table\" has non-zero probability: the frog's hands and eyes bear a resemblance to billiard balls, especially on a green background.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "In many applications of machine learning, users are asked to trust a model to help them make decisions. Despite the fact that many machine learning models are black boxes, understanding the rationale behind the model's predictions would certainly help users decide when to trust or not to trust their predictions. Such assessment is usually done by looking at held-out accuracy or some other aggregate measure. Explaining the Predictions of Any Classifier, a joint work by Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin (to appear in ACM's Conference on Knowledge Discovery and Data Mining -- KDD2016), we explore precisely the question of trust and explanations. We generate an explanation by approximating the underlying model by an interpretable one (such as a linear model with only a few non-zero coefficients), learned on perturbations of the original instance (e.g., removing words or hiding parts of the image). See Figure 3 for an example of how LIME works for image classification. We take the image on the left and divide it into interpretable components (contiguous superpixels). As illustrated in Figure 4, we then generate a data set of perturbed instances by turning some of the interpretable components “off” (in this case, making them gray). For each perturbed instance, we get the probability that a tree frog is in the image according to the model. Explaining a prediction with LIME. It also sheds light on why \"pool table\" has non-zero probability: the frog's hands and eyes bear a resemblance to billiard balls, especially on a green background. Continue reading Introduction to Local Interpretable Model-Agnostic Explanations (LIME).\n",
      "\n",
      "GE's digital transformation\n",
      "===========================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Jeff Immelt on GE’s investments in big data, brilliant factories, and the industrial Internet, and the role of humans in the industrial economy of the 21st century.Continue reading GE's digital transformation.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "\n",
      "\n",
      "Where science-as-a-service and supercomputing meet\n",
      "==================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "SCRN empowers researchers to easily access tools to analyze or share their data and analysis workflows. A Deeper Look: Russell Poldrack and the Center for Reproducible Neuroscience\n",
      "With the meteoric advancement of technology, there is increasing scrutiny about how science is getting done. The Internet has enabled scientific results to be publicized, disseminated, modified, and expanded within minutes. Social media can subsequently propagate that information universally, allowing virtually anyone with access to WiFi to influence—and, therefore, potentially skew—data collection procedures and results. Ultimately, this means that reproducibility of modern science is under attack.Continue reading Where science-as-a-service and supercomputing meet.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "A Deeper Look: Russell Poldrack and the Center for Reproducible Neuroscience\n",
      "With the meteoric advancement of technology, there is increasing scrutiny about how science is getting done. Social media can subsequently propagate that information universally, allowing virtually anyone with access to WiFi to influence—and, therefore, potentially skew—data collection procedures and results.\n",
      "\n",
      "Alyona Medelyan on applications of NLU\n",
      "======================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "The O'Reilly Radar Podcast: Natural language understanding and natural language processing applications, our future with chatbots, and open source indexing.This week, I talk with Alyona Medelyan, co-founder and CEO at Thematic and founder and CEO at Entopix. We talk about natural language understanding, the challenges of analyzing unstructured text, and her open source indexing tool Maui that she's been working on for the past 10 years.Continue reading Alyona Medelyan on applications of NLU.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "We talk about natural language understanding, the challenges of analyzing unstructured text, and her open source indexing tool Maui that she's been working on for the past 10 years.Continue reading Alyona Medelyan on applications of NLU.\n",
      "\n",
      "Enabling enterprise adoption of AI technologies\n",
      "===============================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "The O’Reilly Data Show Podcast: Jana Eggers on building applications that rely on synaptic intelligence.In this episode of the O’Reilly Data Show, I spoke with Jana Eggers, CEO of Nara Logics. Eggers’ involvement with AI dates back to her days as a researcher at the Los Alamos National Laboratory. Most recently she has been helping companies across many industries adopt AI technologies as a way to enable a range of intelligent data applications.Continue reading Enabling enterprise adoption of AI technologies.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Most recently she has been helping companies across many industries adopt AI technologies as a way to enable a range of intelligent data applications.Continue reading Enabling enterprise adoption of AI technologies.\n",
      "\n",
      "Four short links: 11 August 2016\n",
      "================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "My 2004 Prius costs me about $1.50 for an hour of run time. Some are variations on the CRISPR theme; others offer new ways to edit genomes. The policy, which incorporates feedback received during the public comment period, requires new custom-developed source code developed specifically by or for the Federal Government to be made available for sharing and re-use across all Federal agencies. It also includes a pilot program that will require Federal agencies to release at least a portion of new custom-developed Federal source code to the public and support agencies in going beyond that minimum requirement. Continue reading Four short links: 11 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Some are variations on the CRISPR theme; others offer new ways to edit genomes. Continue reading Four short links: 11 August 2016.\n",
      "\n",
      "Best practices for streaming applications\n",
      "=========================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Mark Grover and Ted Malaska offer an overview of projects for streaming applications, including Kafka, Flume, and Spark Streaming, and discuss the architectural schemas available, such as Lambda and Kappa.Continue reading Best practices for streaming applications.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "\n",
      "\n",
      "Five questions for James Turnbull\n",
      "=================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "What makes a good operations professional in this day and age? A good operations professional is diverse and flexible. Once upon a time it may have been possible to pigeonhole an “operation’s person,” usually as a cliched stereotype of a bearded white dude, writing 10,000-line Bash scripts in between craft beers and bitterness. They are empathetic to the needs of their colleagues because they own the experience (and the cost!) It’s hard to narrow it down to just a few presentations!\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "What makes a good operations professional in this day and age? A good operations professional is diverse and flexible. Once upon a time it may have been possible to pigeonhole an “operation’s person,” usually as a cliched stereotype of a bearded white dude, writing 10,000-line Bash scripts in between craft beers and bitterness. They think about business requirements, engage with their peers in helping them build deployable and manageable product, and conduct blameless post-mortems when things go wrong. A good operations professional today cares about user experience, developer happiness, work-life balance, and collaboration. They are empathetic to the needs of their colleagues because they own the experience (and the cost!) of putting those colleagues’ hard-built features and product out into the world. You then work down the stack, identifying the applications, services, and finally hosts that contribute to that health. So is solid training, learning, and mentoring patterns and approaches across all levels of the team; clear understanding of our objectives, and an individual understanding of what you need to do to be successful; and collective ownership of the future of your product, and of important central concerns like availability, security, and performance. I think it’s a great program overall. It’s hard to narrow it down to just a few presentations!\n",
      "\n",
      "Scalable data science with R\n",
      "============================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Without making the data smaller (through sampling, for example) this problem can be solved in two different ways:\n",
      "\n",
      "Scaling-out vertically, by using a machine with more available RAM. Scaling-out horizontally: In this context, it is necessary to change the default R behaviour of loading all required data in memory and access the data differently by using a distributed or parallel schema with a divide-and-conquer (or in R terms, split-apply-combine) approach like MapReduce. After the data preparation step, the next common data science phase consists of training machine learning models, which can also be performed on a single machine or distributed among different machines. H2o framework: a Java-based framework that allows building scalable machine learning models in R or Python. There are other open source CRAN packages to deal with big data, such as biglm, bigpca, biganalytics, bigmemory or pbdR—but they are focused on specific issues rather than addressing the data science pipeline in general.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Despite its popularity, the main drawback of vanilla R is its inherently “single threaded” nature and its need to fit all the data being processed in RAM. Without making the data smaller (through sampling, for example) this problem can be solved in two different ways:\n",
      "\n",
      "Scaling-out vertically, by using a machine with more available RAM. Scaling-out horizontally: In this context, it is necessary to change the default R behaviour of loading all required data in memory and access the data differently by using a distributed or parallel schema with a divide-and-conquer (or in R terms, split-apply-combine) approach like MapReduce. After the data preparation step, the next common data science phase consists of training machine learning models, which can also be performed on a single machine or distributed among different machines. H2o framework: a Java-based framework that allows building scalable machine learning models in R or Python. There are other open source CRAN packages to deal with big data, such as biglm, bigpca, biganalytics, bigmemory or pbdR—but they are focused on specific issues rather than addressing the data science pipeline in general.\n",
      "\n",
      "Four short links: 10 August 2016\n",
      "================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Language Research, Probabilistic Cognition, Medical Data, and Teaching State Computer Security\n",
      "\n",
      "AI's Language Problem (Wired) -- very readable overview of the challenges and research in making more sense of the text we are processing, and why deep learning is a great start but not the end of the work to be done. Probabilistic Models of Cognition -- web book from Stanford profs behind webppl, a probabilistic programming language built on Javascript. Your Medical Data Misappropriated (BoingBoing) -- \"Property\" is a terrible framework for understanding personal information—it's led to a situation where people aren't allowed to know what's going on in their own bodies, and where corporations can use anti-theft laws to attack scientists, security researchers, and the people whose bodies generated the data the corporations have turned into crown jewels. PwC Australia's Game to Teach Cyber Security Lessons (Computer Weekly) -- a friend has played this, says it is really good at conveying the complexity and the relentlessness (and is accessible for normal people). Continue reading Four short links: 10 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Language Research, Probabilistic Cognition, Medical Data, and Teaching State Computer Security\n",
      "\n",
      "AI's Language Problem (Wired) -- very readable overview of the challenges and research in making more sense of the text we are processing, and why deep learning is a great start but not the end of the work to be done. PwC Australia's Game to Teach Cyber Security Lessons (Computer Weekly) -- a friend has played this, says it is really good at conveying the complexity and the relentlessness (and is accessible for normal people).\n",
      "\n",
      "DSP sounds and signals\n",
      "======================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Decompose a sound into its harmonics, modify the harmonics, and generate new sounds.A signal represents a quantity that varies in time. That definition is pretty abstract, so let’s start with a concrete example: sound. A sound signal represents variations in air pressure over time. A microphone is a device that measures these variations and generates an electrical signal that represents sound. Microphones and speakers are called transducers because they transduce, or convert, signals from one form to another.Continue reading DSP sounds and signals.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "That definition is pretty abstract, so let’s start with a concrete example: sound. Microphones and speakers are called transducers because they transduce, or convert, signals from one form to another.Continue reading DSP sounds and signals.\n",
      "\n",
      "A cloud-native approach to logs\n",
      "===============================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Simplifying your application’s log emission process.In Beyond the Twelve-Factor App, I present a new set of guidelines that builds on Heroku’s original 12 factors and reflects today’s best practices for building cloud-native applications. I have changed the order of some to indicate a deliberate sense of priority, and added factors such as telemetry, security, and the concept of “API first” that should be considerations for any application that will be running in the cloud. These new 15-factor guidelines are:\n",
      "\n",
      "One codebase, one application\n",
      "API first\n",
      "Dependency management\n",
      "Design, build, release, and run\n",
      "Configuration, credentials, and code\n",
      "Logs\n",
      "Disposability\n",
      "Backing services\n",
      "Environment parity\n",
      "Administrative processes\n",
      "Port binding\n",
      "Stateless processes\n",
      "Concurrency\n",
      "Telemetry\n",
      "Authentication and authorization\n",
      "\n",
      "Logs (the 11th of the original 12 factors) should be treated as event streams, that is, logs are a sequence of events emitted from an application in time-ordered sequence. The key point about dealing with logs in a cloud-native fashion is, as the original 12 factors indicate, a truly cloud-native application never concerns itself with routing or storage of its output stream.Continue reading A cloud-native approach to logs.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Simplifying your application’s log emission process.In Beyond the Twelve-Factor App, I present a new set of guidelines that builds on Heroku’s original 12 factors and reflects today’s best practices for building cloud-native applications.\n",
      "\n",
      "Patrolling the dark net\n",
      "=======================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "In some cases, the stolen items are recovered within a few days and eventually returned. When cops find stolen goods quickly, it’s most likely because they know where to look. Burglars aren’t interested in keeping your flat-screen monitor and Xbox; they want cash. They bring their loot to a middleman (also known as a fence) who specializes in reselling stolen goods. Usually, the stolen goods sit in the fence’s shed or basement until a buyer is found.Continue reading Patrolling the dark net.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Burglars aren’t interested in keeping your flat-screen monitor and Xbox; they want cash. They bring their loot to a middleman (also known as a fence) who specializes in reselling stolen goods. Usually, the stolen goods sit in the fence’s shed or basement until a buyer is found.Continue reading Patrolling the dark net.\n",
      "\n",
      "XenServer: Core architecture and critical components\n",
      "====================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Core Architecture and Critical Components\n",
      "In not available, we stated that “XenServer is a pre-packaged, Xen-based virtualization solution.” This implies that anyone with sufficient skill can re-create XenServer by starting with the Xen hypervisor. In reality, there is a rather large number of decisions anyone embarking on this task must make, and thankfully the team at Citrix has already made the bulk of those decisions. XenServer Isn’t Linux, but dom0 Is\n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "The misconception that XenServer is Linux is easily arrived at because from installation to privileged user space access, everything looks, feels, and tools much like a standard Linux environment. The boot loader used is extlinux, and the installer uses a familiar dialog for interactive setup and post installation. The administrator ends up within a Linux operating system logged in as the privileged user named root.Continue reading XenServer: Core architecture and critical components.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Core Architecture and Critical Components\n",
      "In not available, we stated that “XenServer is a pre-packaged, Xen-based virtualization solution.” This implies that anyone with sufficient skill can re-create XenServer by starting with the Xen hypervisor. The administrator ends up within a Linux operating system logged in as the privileged user named root.Continue reading XenServer: Core architecture and critical components.\n",
      "\n",
      "A framework for performance\n",
      "===========================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Performance Engineering throughout the lifecycle.As you start to incorporate Performance Engineering capabilities into your lifecycle, it is important to understand what some of these areas are, and put these into context with some typical flow nomenclature. In the following sections we define each of these key elements\n",
      "with specifics—what, why, and how—so you have a more complete understanding of how to add Performance Engineering throughout the lifecycle. One of the challenges in building Effective Performance Engineering or a performance-first culture is defining who does what, when, and how. This kind of organizational alignment and agreement is as important as the daily scrum meeting of an Agile team. If everyone agrees that performance is important, but not on how to address it, then nothing is done about it.Continue reading A framework for performance .\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "In the following sections we define each of these key elements\n",
      "with specifics—what, why, and how—so you have a more complete understanding of how to add Performance Engineering throughout the lifecycle. This kind of organizational alignment and agreement is as important as the daily scrum meeting of an Agile team.\n",
      "\n",
      "API caching: Extending app architecture performance and security\n",
      "================================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Learn how to configure and automate API caching for maximum performance and broad protection.Continue reading API caching: Extending app architecture performance and security.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "\n",
      "\n",
      "Why ACID transactions matter in an eventually consistent world\n",
      "==============================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Many developers have moved to distributed computing models with weaker consistency guarantees in exchange for that sweet, sweet speed. This is somewhat true—very few systems that claim to support 100% ACID transactions actually do. While it’s crucial in some—especially in high-transaction speed industries like financial services—a mostly-ACID system could work in others. However, many database implementers don’t or can’t know what “mostly” means for their operations. However, not everyone has a warehouse full of them waiting for a big distributed computing project.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Fast forward to present-day. Many developers have moved to distributed computing models with weaker consistency guarantees in exchange for that sweet, sweet speed. This is somewhat true—very few systems that claim to support 100% ACID transactions actually do. While it’s crucial in some—especially in high-transaction speed industries like financial services—a mostly-ACID system could work in others. However, many database implementers don’t or can’t know what “mostly” means for their operations. However, not everyone has a warehouse full of them waiting for a big distributed computing project.\n",
      "\n",
      "Running Spark on Alluxio with S3\n",
      "================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Calvin Jia presents an in-depth overview of Alluxio and its role in the big data ecosystem. In this segment, he reviews examples that show how Alluxio complements Spark and S3, to enable fast data access.Continue reading Running Spark on Alluxio with S3.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Calvin Jia presents an in-depth overview of Alluxio and its role in the big data ecosystem.\n",
      "\n",
      "Four short links: 9 August 2016\n",
      "===============================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Selectron -- GUI and command-line SQL client. ConceptNet -- a semantic network containing a lot of things computers should know about the world, especially when understanding text written by people. Patch the Process -- games often release massive day-one patches because the console QA process (and the timeline to ship discs) means the devs have fixed things for months after the version that was approved for sale. This post explains that source of lag in more detail, and should make automated testing folks twitch. Continue reading Four short links: 9 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "ConceptNet -- a semantic network containing a lot of things computers should know about the world, especially when understanding text written by people. Patch the Process -- games often release massive day-one patches because the console QA process (and the timeline to ship discs) means the devs have fixed things for months after the version that was approved for sale. Continue reading Four short links: 9 August 2016.\n",
      "\n",
      "Design in venture capital\n",
      "=========================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Venture capital firms with multimillion-dollar portfolios have recently begun to add design partners to work with startups during their formative stages. Introduction\n",
      "“How can I get a job like yours?” “How do you spend your time?” “What does a design partner in a venture capital firm do?” The frequency of these questions posed to me since joining Khosla Ventures two years ago prompted me to write this report. The role of design partner inside venture capital (VC) firms is still relatively new and undefined, with a little more than a handful of people holding this job title on Sand Hill Road. So, it’s no surprise that there would be considerable curiosity, interest, and excitement about this role as a possible career choice for designers. My goals in writing this report are threefold: Continue reading Design in venture capital.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "The role of design partner inside venture capital (VC) firms is still relatively new and undefined, with a little more than a handful of people holding this job title on Sand Hill Road.\n",
      "\n",
      "Build to lead: How Lego bricks can make you a better leader\n",
      "===========================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Explore Lego Serious Play, a proven tool for boosting both individual and team productivity. Build to Lead: How Lego Bricks Can Make You a Better Leader\n",
      "\n",
      "Harnessing the Power of Play at Work\n",
      "What if you could harness the power of play—something we all knew but most of us forgot—to empower your teams, and at the same time help you realize creative and powerful solutions in the face of today’s business challenges? It sounds almost too good to be true, but, yes, playing with Lego bricks can help make you and your team more productive (see Figure 1-1). And who doesn’t love an excuse to play with Lego bricks? It’s an incredibly effective way to get everyone’s ideas on the table and, together, develop a collective plan of action (see Figure 1-2).Continue reading Build to lead: How Lego bricks can make you a better leader.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Explore Lego Serious Play, a proven tool for boosting both individual and team productivity. It sounds almost too good to be true, but, yes, playing with Lego bricks can help make you and your team more productive (see Figure 1-1). It’s an incredibly effective way to get everyone’s ideas on the table and, together, develop a collective plan of action (see Figure 1-2).Continue reading Build to lead: How Lego bricks can make you a better leader.\n",
      "\n",
      "Four short links: 8 August 2016\n",
      "===============================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Star Simpson, Inside Malware Network, Code Generation, and Trippy Face Tricks\n",
      "\n",
      "Interview with Star Simpson (BoingBoing) -- Foo and my personal superhero on the Cool Tools podcast. Wire Wire: A West African Cyber Threat -- fascinating look inside the malware Nigerian scammers use. (via BoingBoing)\n",
      "\n",
      "Latent Predictor Networks for Code Generation (PDF) -- Using this framework, we address the problem of generating programming code from a mixed natural language and structured specification. Omote Demonstration (YouTube) -- stunning real-time face tracking and projection mapping system. (via BoingBoing)\n",
      "\n",
      "Continue reading Four short links: 8 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Star Simpson, Inside Malware Network, Code Generation, and Trippy Face Tricks\n",
      "\n",
      "Interview with Star Simpson (BoingBoing) -- Foo and my personal superhero on the Cool Tools podcast. (via BoingBoing)\n",
      "\n",
      "Latent Predictor Networks for Code Generation (PDF) -- Using this framework, we address the problem of generating programming code from a mixed natural language and structured specification. Omote Demonstration (YouTube) -- stunning real-time face tracking and projection mapping system. (via BoingBoing)\n",
      "\n",
      "Continue reading Four short links: 8 August 2016.\n",
      "\n",
      "Improving operations using data analytics\n",
      "=========================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "A straightforward approach to making staffing decisions might involve estimating a couple of metrics: (1) the baseline productivity of a single staff member (e.g. The data table stub below shows a sample of what such a time series table might look like. Since staffing schedules may change periodically, often on a monthly basis, we also limit the analysis to tickets created during the specific period of time when a particular schedule was in effect. Comparing the RMSE calculated, after removing the outlying point for either fit, does not indicate a substantial difference (1.4 versus 1.5), and it’s also apparent by visual inspection that neither fit provides much predictive value. Initial response time vs. staffing level\n",
      "Another relationship we should examine is between the staffing level and the average initial response time.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Two areas in particular where data analytics can help companies is (1) improved service delivery to customers, and (2) more efficient and effective resource allocation. A straightforward approach to making staffing decisions might involve estimating a couple of metrics: (1) the baseline productivity of a single staff member (e.g. The data table stub below shows a sample of what such a time series table might look like. Since staffing schedules may change periodically, often on a monthly basis, we also limit the analysis to tickets created during the specific period of time when a particular schedule was in effect. This plot shows the average initial response time, by hour of day that a ticket was created (in red). Comparing the RMSE calculated, after removing the outlying point for either fit, does not indicate a substantial difference (1.4 versus 1.5), and it’s also apparent by visual inspection that neither fit provides much predictive value. Initial response time vs. staffing level\n",
      "Another relationship we should examine is between the staffing level and the average initial response time. In this example, we have shown how combining straightforward analyses of a company’s ticket management data with information about its staffing scheduling can help a support operations manager make better staff scheduling decisions.\n",
      "\n",
      "Four short links: 5 August 2016\n",
      "===============================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Challenge Winner, Rewriting Rules, Games for Ground Truth, and Fast Text Processing\n",
      "\n",
      "NIH Pill Image Recognition Challenge -- congrats to Foo Greg Sadetsky, whose team took 2nd place! Time to Rewrite The Rules (Tim O'Reilly) -- You can see here that there is a five-player game in which gains (or losses) can be allocated in different proportion to consumers, the company itself, financial markets, workers, or taxpayers. The current rules of our economy have encouraged the allocation of gains to consumers and financial shareholders (now including top company management), and the losses to workers and taxpayers. Ground Truth from Computer Games -- clever hack: using photorealistic games to train image segmenting algorithms. Continue reading Four short links: 5 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Challenge Winner, Rewriting Rules, Games for Ground Truth, and Fast Text Processing\n",
      "\n",
      "NIH Pill Image Recognition Challenge -- congrats to Foo Greg Sadetsky, whose team took 2nd place! The current rules of our economy have encouraged the allocation of gains to consumers and financial shareholders (now including top company management), and the losses to workers and taxpayers. Ground Truth from Computer Games -- clever hack: using photorealistic games to train image segmenting algorithms.\n",
      "\n",
      "There’s nothing magical about learning data science\n",
      "===================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Nor do I think there is anything magical about learning data science skills. The premise of the tutorial is that you can follow a direct path toward professional data science, by taking on the following, most distinguishing habits:\n",
      "5. In the tutorial, I’ll teach techniques for building and using data pipelines to make sure you always have enough data to do something useful. A data strategy map. Remember those experiments you performed, wrote reports about, and presented in grammar-school science class?\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Nor do I think there is anything magical about learning data science skills. You can pick up the basics of machine learning in about 15 hours of lectures and videos. You can become reasonably good at most things with about 20 hours (45 minutes a day for a month) of focused, deliberate practice. The premise of the tutorial is that you can follow a direct path toward professional data science, by taking on the following, most distinguishing habits:\n",
      "5. In a well-written story, the author starts with an important question, walks you through the data gathered to answer the question, describes the experiments run, and presents resulting conclusions. In the tutorial, I’ll teach techniques for building and using data pipelines to make sure you always have enough data to do something useful. Knowing that “the D2 pawn can move to D3 unless there is an obstruction at D3 or the move exposes the king to direct attack” is necessary to play the game, but it doesn’t help me pick a winning move. A data strategy map. Remember those experiments you performed, wrote reports about, and presented in grammar-school science class? There is a great need for people who can imagine data-driven improvements, make them real, and drive change. Continue reading There’s nothing magical about learning data science.\n",
      "\n",
      "O'Reilly Online Training: Data-Driven UX Design\n",
      "===============================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "10 a.m. PT September 22, 2016. Join UX strategist and business consultant Heather O’Neill, CEO of Pixels for Humans, for a hands-on, in-depth exploration of creating and improving designs using data. Continue reading O'Reilly Online Training: Data-Driven UX Design.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Join UX strategist and business consultant Heather O’Neill, CEO of Pixels for Humans, for a hands-on, in-depth exploration of creating and improving designs using data.\n",
      "\n",
      "The game of business: It's time to rewrite the rules\n",
      "====================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "As labor organizer David Rolf said to me, \"God did not make being an auto worker a good job!\" Right now, we're at an inflection point, where many rules are being profoundly rewritten. Right now, the economic game is enormously fun for far too few players, and an increasingly miserable experience for many others. Football (soccer) has changed its rules many times over the past 150 years. But it might save taxpayers $6 billion per year (and that’s just the amount used to subsidize Walmart; including all the other low-wage employers in America, the number is far larger.)\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Some of the rules represent what appear to be fundamental constraints—the availability of resources, say, or the absorptive capacity of the environment, or even the behavioral patterns of human nature—while others are arbitrary and subject to change, such as tax policy, government entitlements, and minimum wage requirements. I was arguing that just as Google's search algorithm takes many factors into account in producing the \"best\" results, Uber's algorithm would benefit if it took drivers' wages, job satisfaction, and turnover into account, and not just passenger pickup time, which is its current fitness function. Figure 1. via Wikispaces\n",
      "\n",
      "Uber’s real-time matching algorithm satisfies two overlapping demand curves. If there are not enough passengers, the price must go down to stimulate passenger demand. I suspect that over time, driver wages will need to increase at some rate that is independent of the simple supply and demand curves that characterize Uber's algorithm today. And that competition may well provide further evidence that higher wages can pay for themselves by inducing productivity and greater consumer satisfaction. As labor organizer David Rolf said to me, \"God did not make being an auto worker a good job!\" Right now, we're at an inflection point, where many rules are being profoundly rewritten. Right now, the economic game is enormously fun for far too few players, and an increasingly miserable experience for many others. But meanwhile, Walmart workers are paid so little that most need government assistance to live—by coincidence, the difference between Walmart wages and a $15 minimum wage for their U.S. workers (approximately $5 billion/year) is not that far off from the $6 billion/year that Walmart workers are subsidized via Federal supplemental nutrition assistance (SNAP, formerly known as “food stamps”). Football (soccer) has changed its rules many times over the past 150 years. But it might save taxpayers $6 billion per year (and that’s just the amount used to subsidize Walmart; including all the other low-wage employers in America, the number is far larger.) If Walmart were to reduce its profits by $5 billion (approximately 20%), its market cap might fall, a loss to shareholders. Those higher prices might discourage some customers, but the higher incomes of workers might encourage them to spend more.\n",
      "\n",
      "Giles Colborne on how AI is reinventing design\n",
      "==============================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "The O’Reilly Design Podcast: AI, understanding algorithms, and design diversity.In this week’s Design Podcast, I sit down with Giles Colborne, designer, author, and managing director of cxpartners. We talk about how AI is reinventing design and the roles of designers; the balance of creating something that is different but familiar; and how, at its most basic level, AI is shortcutting user input.Continue reading Giles Colborne on how AI is reinventing design.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "The O’Reilly Design Podcast: AI, understanding algorithms, and design diversity.In this week’s Design Podcast, I sit down with Giles Colborne, designer, author, and managing director of cxpartners.\n",
      "\n",
      "Uber’s case for incremental processing on Hadoop\n",
      "================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "This makes sense in the less-than-five-minute latency windows such pipelines operate on. By performing incremental processing using existing, much more mature SQL engines in the Hadoop ecosystem, we can leverage the solid foundations that have gone into building them. The idea illustrated in the figure above is fairly simple. The most common cause for lack of completeness is late-arriving data (as explained in detail in this Google Cloud Dataflow deck). However, in Hadoop, recomputing typically just means rewriting the entire (immutable) Hive partition (or a folder inside HDFS for simplicity) and recomputing all jobs that consumed that Hive partition.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Batch processing can tackle massive scale and provides mature SQL support via Spark SQL/Hive, but the processing styles typically involve larger latency. This makes sense in the less-than-five-minute latency windows such pipelines operate on. By performing incremental processing using existing, much more mature SQL engines in the Hadoop ecosystem, we can leverage the solid foundations that have gone into building them. In the incremental processing model, the problem naturally becomes simpler due to relatively longer windows, allowing more room for the streams to align across a processing window. On the other hand, if correctness is more important, SQL provides an easier way to expand the join window selectively and reprocess. Another important advancement in such SQL engines is the support for columnar file formats like ORC/Parquet, which have significant advantages for analytical workloads. The idea illustrated in the figure above is fairly simple. The most common cause for lack of completeness is late-arriving data (as explained in detail in this Google Cloud Dataflow deck). Late data forces recomputation of the time windows (typically, Hive partitions in Hadoop), over which results might have been computed already and even communicated to the end user. However, in Hadoop, recomputing typically just means rewriting the entire (immutable) Hive partition (or a folder inside HDFS for simplicity) and recomputing all jobs that consumed that Hive partition. Typically, consumers learn this by scanning the entire partition/table and recomputing everything, which can take a lot of time and resources. Thus, we also need a mechanism to more efficiently obtain the records that have changed since the last time the partition was consumed.\n",
      "\n",
      "Four short links: 4 August 2016\n",
      "===============================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Make Music, HTTP/2 Push, d3 Scaffolding, and Elan Lee Interview\n",
      "\n",
      "Marble Musical Machine (YouTube) -- beautiful example of the nerd tinkerer's art. (via Eric Bidelman)\n",
      "\n",
      "How I Start d3 Projects (Chris McDowall) -- This is the little bit of scaffolding I typically use when starting a d3.js project. Interview with Elan Lee -- podcast, no transcription, unfortunately. Now, it's becoming much more attractive to exchange money for an experience. Continue reading Four short links: 4 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Make Music, HTTP/2 Push, d3 Scaffolding, and Elan Lee Interview\n",
      "\n",
      "Marble Musical Machine (YouTube) -- beautiful example of the nerd tinkerer's art. (via Eric Bidelman)\n",
      "\n",
      "How I Start d3 Projects (Chris McDowall) -- This is the little bit of scaffolding I typically use when starting a d3.js project.\n",
      "\n",
      "HiveBio: Access Granted\n",
      "=======================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Bergen McMurray has cherry-red hair and shoulders painted with black ink tattoos. You probably wouldn’t be surprised to learn that she’s worked as an artist, a photographer, and a graphic designer. Do-it-yourself biology, or DIYbio, is part of a growing movement which seeks to give people the tools to learn without formal education. DIYbio empowers the individual to seek scientific knowledge through trial and error, getting hands dirty in books and bench work alike. In the same way computer tinkering and garage electronics powered the human element of the digital revolution, DIYbio provides the average individual a pathway to biological literacy.Continue reading HiveBio: Access Granted.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "DIYbio empowers the individual to seek scientific knowledge through trial and error, getting hands dirty in books and bench work alike. In the same way computer tinkering and garage electronics powered the human element of the digital revolution, DIYbio provides the average individual a pathway to biological literacy.Continue reading HiveBio: Access Granted.\n",
      "\n",
      "Chris Eng on the challenges of improved application security\n",
      "============================================================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "The O’Reilly Security Podcast: Vulnerabilities in assembled software and the need for immediate developer feedback.In this episode, I talk with Chris Eng, vice president of research at Veracode, a software security-as-a-service business. We discuss Veracode’s research on application security across a broad spectrum of industries, the challenges of securing modern “assembled” software, and making it easier for developers to bake in security from the get-go.Continue reading Chris Eng on the challenges of improved application security.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "The O’Reilly Security Podcast: Vulnerabilities in assembled software and the need for immediate developer feedback.In this episode, I talk with Chris Eng, vice president of research at Veracode, a software security-as-a-service business.\n",
      "\n",
      "Four short links: 3 August 2016\n",
      "===============================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Aussie Startups, Exponential Tech, Server-side TLS, and Hololens GA\n",
      "\n",
      "Australian Startup Scene (Tristan Pollock) -- the Australia and New Zealand VC ecosystem has grown eight times bigger since 2011 and broke $600 million in funding for the first time ever. Cartoon Intro to Exponential Tech (Kaila Colbin) -- the human brain's struggle with exponential series is the governor on our imagination. Server-Side TLS (Mozilla) -- The Operations Security (OpSec) team maintains this document as a reference guide to navigate the TLS landscape. Hololens Goes GA -- USD3k per, max 5/customer. Continue reading Four short links: 3 August 2016.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Aussie Startups, Exponential Tech, Server-side TLS, and Hololens GA\n",
      "\n",
      "Australian Startup Scene (Tristan Pollock) -- the Australia and New Zealand VC ecosystem has grown eight times bigger since 2011 and broke $600 million in funding for the first time ever.\n",
      "\n",
      "Introduction to OKRs\n",
      "====================\n",
      "\n",
      "TOP N summary\n",
      "-------------\n",
      "Objectives and Key Results (OKRs) have helped organizations like Google and LinkedIn achieve their goals. Introduction\n",
      "Why is there so much interest in Objectives and Key Results, or OKRs? When Silicon Valley startups discovered OKRs were behind the meteoric rise of companies such as Google, LinkedIn, Twitter, and Zynga, company after company decided to adopt OKRs, hoping to catch even a fraction of that success. There is no question that OKRs work. This report will share how the best companies use them to create focus, unity, and velocity.Continue reading Introduction to OKRs.\n",
      "\n",
      "Mean Scored Summary\n",
      "-------------------\n",
      "Objectives and Key Results (OKRs) have helped organizations like Google and LinkedIn achieve their goals. When Silicon Valley startups discovered OKRs were behind the meteoric rise of companies such as Google, LinkedIn, Twitter, and Zynga, company after company decided to adopt OKRs, hoping to catch even a fraction of that success. This report will share how the best companies use them to create focus, unity, and velocity.Continue reading Introduction to OKRs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for post in blog_data:\n",
    "    \n",
    "    post.update(summarize(post['content']))\n",
    "    \n",
    "    print(post['title'])\n",
    "    print('='*len(post['title']))\n",
    "    print()\n",
    "    print('TOP N summary')\n",
    "    print('-------------')\n",
    "    print(' '.join(post['top_n_summary']))\n",
    "    print()\n",
    "    print('Mean Scored Summary')\n",
    "    print('-------------------')\n",
    "    print(' '.join(post['mean_scored_summary']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
